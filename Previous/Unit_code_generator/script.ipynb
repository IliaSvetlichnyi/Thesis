{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error:   File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 18\n",
      "    Remember to adjust the file path and column names according to your specific dataset.\n",
      "             ^^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 4, in <module>\n",
      "    df = pd.read_csv('/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 1 fields in line 12, saw 3\n",
      "\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 3, in <module>\n",
      "    df = pd.read_csv('/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_data.csv')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_data.csv'\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 3, in <module>\n",
      "    df = pd.read_csv('/path/to/your/file.csv')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/your/file.csv'\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 3, in <module>\n",
      "    df = pd.read_csv('/Users/ilya/Desktop/insurance.csv')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/ilya/Desktop/insurance.csv'\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 3, in <module>\n",
      "    df = pd.read_csv('/Users/ilya/Desktop/insurance.csv')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/ilya/Desktop/insurance.csv'\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 3, in <module>\n",
      "    df = pd.read_csv('/Users/ilya/Desktop/insurance.csv')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/ilya/Desktop/insurance.csv'\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 3, in <module>\n",
      "    df = pd.read_csv('/Users/ilya/Desktop/insurance.csv')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/ilya/Desktop/insurance.csv'\n",
      "\n",
      "Validation failed for step: Handle missing values (remove or impute)\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_4_code.py\", line 3, in <module>\n",
      "    df = pd.read_csv('/Users/ilya/Desktop/datasets/insurance.csv')\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/ilya/Desktop/datasets/insurance.csv'\n",
      "\n",
      "Validation failed for step: Split the data into training and testing sets\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_6_code.py\", line 2, in <module>\n",
      "    train_data, test_data = train_test_split(your_placeholder_here + '/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/insurance.csv', \n",
      "NameError: name 'your_placeholder_here' is not defined\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 20, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 20, in <module>\n",
      "    X_train, X_test, y_train, y_test  = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 18, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 18, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 20, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 18, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 18, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 18, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 20, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 20, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n",
      "Validation failed for step: Choose appropriate machine learning algorithms based on the problem type\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator/step_7_code.py\", line 18, in <module>\n",
      "    X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/frame.py\", line 5568, in drop\n",
      "    return super().drop(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4785, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/generic.py\", line 4827, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['target'] not found in axis\"\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 249\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome code snippets failed validation. Documentation not generated.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 198\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation failed for step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 198\u001b[0m fixed_code_snippet \u001b[38;5;241m=\u001b[39m \u001b[43mfix_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcleaned_code_snippet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(code_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    201\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(fixed_code_snippet)\n",
      "Cell \u001b[0;32mIn[2], line 140\u001b[0m, in \u001b[0;36mfix_code\u001b[0;34m(code_snippet, error_message, csv_path)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfix_code\u001b[39m(code_snippet, error_message, csv_path):\n\u001b[1;32m    135\u001b[0m     request \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following code snippet encountered an error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcode_snippet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError message:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease fix the code snippet to resolve the error without providing any explanations or comments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[0;32m--> 140\u001b[0m     fixed_code \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_code_snippet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     cleaned_fixed_code \u001b[38;5;241m=\u001b[39m clean_and_correct_code(fixed_code, csv_path)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_fixed_code\n",
      "Cell \u001b[0;32mIn[2], line 57\u001b[0m, in \u001b[0;36mgenerate_code_snippet\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_code_snippet\u001b[39m(request):\n\u001b[1;32m     55\u001b[0m     formatted_request \u001b[38;5;241m=\u001b[39m chat_prompt\u001b[38;5;241m.\u001b[39mformat_prompt(\n\u001b[1;32m     56\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest)\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[0;32m---> 57\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     generated_code \u001b[38;5;241m=\u001b[39m response\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated_code\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_community/llms/ollama.py:421\u001b[0m, in \u001b[0;36mOllama._generate\u001b[0;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m--> 421\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_community/llms/ollama.py:330\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[1;32m    329\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[1;32m    332\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/langchain_community/llms/ollama.py:172\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[0;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    166\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    170\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    171\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[1;32m    173\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[1;32m    174\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    175\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    177\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[1;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[1;32m    871\u001b[0m ):\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/utils.py:572\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[0;34m(iterator, r)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    571\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    573\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/response.py:1040\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/response.py:1184\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/response.py:1108\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the workflow steps with assigned numbers\n",
    "workflow_steps = {\n",
    "    11: \"Load the CSV file into a suitable format (e.g., DataFrame)\",\n",
    "    21: \"Examine the structure and characteristics of the data\",\n",
    "    22: \"Identify missing values, data types, and statistical summary\",\n",
    "    23: \"Visualize the data using charts, graphs, or plots\",\n",
    "    24: \"Gain insights and formulate hypotheses\",\n",
    "    31: \"Handle missing values (remove or impute)\",\n",
    "    32: \"Convert categorical variables to numerical representations\",\n",
    "    33: \"Perform feature scaling or normalization\",\n",
    "    34: \"Encode categorical variables (one-hot encoding, label encoding, etc.)\",\n",
    "    35: \"Split the data into training and testing sets\",\n",
    "    41: \"Create new features based on domain knowledge or data insights\",\n",
    "    42: \"Combine or transform existing features\",\n",
    "    43: \"Perform feature selection to identify relevant features\",\n",
    "    51: \"Choose appropriate machine learning algorithms based on the problem type\",\n",
    "    52: \"Define the model architecture and hyperparameters\",\n",
    "    53: \"Train the selected model on the training data\",\n",
    "    54: \"Utilize techniques like cross-validation for model evaluation\",\n",
    "    61: \"Evaluate the trained model's performance on the testing data\",\n",
    "    62: \"Calculate evaluation metrics (e.g., accuracy, precision, recall, F1-score)\",\n",
    "    63: \"Visualize the model's performance using confusion matrix, ROC curve, etc.\",\n",
    "    64: \"Fine-tune the model if necessary\",\n",
    "    71: \"Analyze the model's coefficients or feature importances\",\n",
    "    72: \"Visualize the model's decision boundaries or learned patterns\",\n",
    "    73: \"Interpret the model's predictions and explain its behavior\",\n",
    "    81: \"Generate unit code documentation during the code generation process\",\n",
    "    82: \"Execute the combined code and capture relevant outputs and insights\",\n",
    "    83: \"Create a comprehensive documentation for the entire workflow, including project overview, dataset details, selected steps, results, and interpretations\",\n",
    "    84: \"Present the documentation to users for understanding and reference\"\n",
    "}\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate only the code snippets without any explanations or comments.\"),\n",
    "    human_prompt\n",
    "])\n",
    "\n",
    "model = Ollama(model=\"llama3\")\n",
    "\n",
    "# Function to generate code with LLM\n",
    "\n",
    "\n",
    "def generate_code_snippet(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to generate code with placeholder data\n",
    "\n",
    "\n",
    "def generate_code_snippet_with_placeholder(request, placeholder_data):\n",
    "    placeholder_request = request + \\\n",
    "        f\"\\nUse the following placeholder data:\\n{placeholder_data}\"\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=placeholder_request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_and_correct_code(generated_code, csv_path):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    cleaned_code_lines = cleaned_code.split(\"\\n\")\n",
    "    cleaned_code_lines = [\n",
    "        line for line in cleaned_code_lines if not line.lower().startswith(\"here is the\")]\n",
    "    cleaned_code = \"\\n\".join(cleaned_code_lines)\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    corrected_code = cleaned_code.replace(\"{csv_path}\", f\"{csv_path}\")\n",
    "    return corrected_code\n",
    "\n",
    "# Load dataset information\n",
    "\n",
    "\n",
    "def get_dataset_info(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    columns = df.columns.tolist()\n",
    "    types = df.dtypes.to_dict()\n",
    "    sample_data = df.head().to_dict(orient='list')\n",
    "    value_counts = {col: df[col].value_counts().to_dict()\n",
    "                    for col in df.columns}\n",
    "    description = df.describe().to_dict()\n",
    "    return columns, types, sample_data, value_counts, description\n",
    "\n",
    "# Function to get selected workflow steps based on step numbers\n",
    "\n",
    "\n",
    "def get_selected_steps(step_numbers):\n",
    "    selected_steps = [workflow_steps[num]\n",
    "                      for num in step_numbers if num in workflow_steps]\n",
    "    return selected_steps\n",
    "\n",
    "# Function to validate a single unit code snippet\n",
    "\n",
    "\n",
    "def validate_unit_code(code_filename):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", code_filename], capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(result.stderr)\n",
    "        return True, result.stdout\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Function to generate documentation for a step\n",
    "def generate_documentation(step, columns_info, types_info, sample_data_info, value_counts_info, description_info):\n",
    "    request = (\n",
    "        f\"Provide a clear and concise description of the job performed by the code for the following step: {step}. \"\n",
    "        f\"The description should summarize the main tasks and key points without going into the specifics of the code. \"\n",
    "        f\"The dataset has the following columns: {columns_info}. \"\n",
    "        f\"The data types are: {types_info}. Sample data: {sample_data_info}. Value counts: {value_counts_info}. \"\n",
    "        f\"Description: {description_info}.\"\n",
    "    )\n",
    "    documentation = generate_code_snippet(request)\n",
    "    return documentation\n",
    "\n",
    "# Function to fix the code based on the error\n",
    "def fix_code(code_snippet, error_message, csv_path):\n",
    "    request = (\n",
    "        f\"The following code snippet encountered an error:\\n\\n{code_snippet}\\n\\n\"\n",
    "        f\"Error message:\\n{error_message}\\n\\n\"\n",
    "        f\"Please fix the code snippet to resolve the error without providing any explanations or comments.\"\n",
    "    )\n",
    "    fixed_code = generate_code_snippet(request)\n",
    "    cleaned_fixed_code = clean_and_correct_code(fixed_code, csv_path)\n",
    "    return cleaned_fixed_code\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/insurance.csv\"\n",
    "    columns, types, sample_data, value_counts, description = get_dataset_info(\n",
    "        csv_path)\n",
    "\n",
    "    columns_info = \", \".join(columns)\n",
    "    types_info = \", \".join([f\"{col}: {typ}\" for col, typ in types.items()])\n",
    "    sample_data_info = \", \".join(\n",
    "        [f\"{col}: {vals[:5]}\" for col, vals in sample_data.items()])\n",
    "    value_counts_info = \", \".join(\n",
    "        [f\"{col}: {dict(list(vc.items())[:5])}\" for col, vc in value_counts.items()])\n",
    "    description_info = \", \".join(\n",
    "        [f\"{col}: {desc}\" for col, desc in description.items()])\n",
    "\n",
    "    # Hardcode the selected step numbers (replace with dynamic selection later)\n",
    "    selected_step_numbers = [ 11, 21, 22, 31, 32, 35, 51, 52, 53, 61, 62]\n",
    "\n",
    "    # Get selected workflow steps based on step numbers\n",
    "    selected_steps = get_selected_steps(selected_step_numbers)\n",
    "\n",
    "    # Generate and validate code snippets for each selected step\n",
    "    unit_code_filenames = []\n",
    "    documentation_snippets = []\n",
    "    combined_code = \"\"\n",
    "    placeholder_data = \"\"\n",
    "    for i, step in enumerate(selected_steps):\n",
    "        request = (\n",
    "            f\"Write a Python code snippet for the following step: {step}. \"\n",
    "            f\"Use placeholders like {csv_path} for dynamic inputs. The dataset has the following columns: {columns_info}. \"\n",
    "            f\"The data types are: {types_info}. Sample data: {sample_data_info}. Value counts: {value_counts_info}. \"\n",
    "            f\"Description: {description_info}. Only return the code without any explanations.\"\n",
    "        )\n",
    "\n",
    "        if i < len(selected_steps) - 1:\n",
    "            if placeholder_data:\n",
    "                code_snippet = generate_code_snippet_with_placeholder(\n",
    "                    request, placeholder_data)\n",
    "            else:\n",
    "                code_snippet = generate_code_snippet(request)\n",
    "\n",
    "            cleaned_code_snippet = clean_and_correct_code(\n",
    "                code_snippet, csv_path)\n",
    "\n",
    "            code_filename = f\"step_{i+1}_code.py\"\n",
    "            with open(code_filename, \"w\") as file:\n",
    "                file.write(cleaned_code_snippet)\n",
    "\n",
    "            fixed_code_snippet = cleaned_code_snippet  # Initialize fixed_code_snippet\n",
    "            success, output = validate_unit_code(code_filename)\n",
    "            while not success:\n",
    "                print(f\"Validation failed for step: {step}\")\n",
    "                print(f\"Error: {output}\")\n",
    "                fixed_code_snippet = fix_code(\n",
    "                    cleaned_code_snippet, output, csv_path)\n",
    "                with open(code_filename, \"w\") as file:\n",
    "                    file.write(fixed_code_snippet)\n",
    "                success, output = validate_unit_code(code_filename)\n",
    "\n",
    "            placeholder_data += output + \"\\n\"  # Append the output to placeholder data\n",
    "\n",
    "            unit_code_filenames.append(code_filename)\n",
    "            documentation_snippet = generate_documentation(\n",
    "                step, columns_info, types_info, sample_data_info, value_counts_info, description_info)\n",
    "            documentation_snippets.append(documentation_snippet)\n",
    "            combined_code += fixed_code_snippet + \"\\n\\n\"\n",
    "        # Combine code snippets and validate for the last step (model training and evaluation)\n",
    "        else:\n",
    "            cleaned_code_snippet = clean_and_correct_code(\n",
    "                code_snippet, csv_path)\n",
    "            fixed_combined_code = cleaned_code_snippet  # Initialize fixed_combined_code\n",
    "            combined_code += cleaned_code_snippet + \"\\n\\n\"\n",
    "            with open(\"combined_code.py\", \"w\") as file:\n",
    "                file.write(combined_code)\n",
    "\n",
    "            success, output = validate_unit_code(\"combined_code.py\")\n",
    "            while not success:\n",
    "                print(f\"Validation failed for step: {step}\")\n",
    "                print(f\"Error: {output}\")\n",
    "                fixed_combined_code = fix_code(combined_code, output, csv_path)\n",
    "                with open(\"combined_code.py\", \"w\") as file:\n",
    "                    file.write(fixed_combined_code)\n",
    "                success, output = validate_unit_code(\"combined_code.py\")\n",
    "\n",
    "            if success:\n",
    "                unit_code_filenames.append(code_filename)\n",
    "                documentation_snippet = generate_documentation(\n",
    "                    step, columns_info, types_info, sample_data_info, value_counts_info, description_info)\n",
    "                documentation_snippets.append(documentation_snippet)\n",
    "            else:\n",
    "                print(f\"Validation failed for step: {step}\")\n",
    "                print(f\"Error: {output}\")\n",
    "                break\n",
    "\n",
    "    # Save documentation to a separate file if all steps are validated successfully\n",
    "    if len(unit_code_filenames) == len(selected_steps):\n",
    "        with open(\"documentation.txt\", \"w\") as file:\n",
    "            file.write(\"\\n\".join(documentation_snippets))\n",
    "        print(\"Documentation saved to documentation.txt\")\n",
    "    else:\n",
    "        print(\"Some code snippets failed validation. Documentation not generated.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
