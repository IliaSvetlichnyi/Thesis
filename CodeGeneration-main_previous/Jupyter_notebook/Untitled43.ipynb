{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Avxs7YTNJS_O"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from loguru import logger\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from typing import List, Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbDnn4mCc7fC"
      },
      "source": [
        "# Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qamardauLDJP"
      },
      "outputs": [],
      "source": [
        "class Step:\n",
        "    def __init__(self,\n",
        "                 step_id: str,\n",
        "                 description: str,\n",
        "                 dependencies: List[str],\n",
        "                 input_vars: List[str],\n",
        "                 output_vars: List[str],\n",
        "                 additional_info):\n",
        "        self.step_id = step_id\n",
        "        self.desiption = description\n",
        "        self.dependencies = dependencies\n",
        "        self.input_vars = input_vars\n",
        "        self.output_vars = output_vars\n",
        "        self.additional_info = additional_info\n",
        "\n",
        "    def __str__(self):\n",
        "      return f\"Step({repr(self.__dict__)})\"\n",
        "\n",
        "    def __repr__(self):\n",
        "      return str(self)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHKIoUKscqaU"
      },
      "source": [
        "# Language Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eip6KSBqOBRl"
      },
      "outputs": [],
      "source": [
        "class OpenAiLlamaApi:\n",
        "    def __init__(self, api_url, api_key,  model_tag):\n",
        "        self.api_url = api_url\n",
        "        self.api_key = api_key\n",
        "        self.model_tag = model_tag\n",
        "\n",
        "    def execute_request(self, request):\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model\": self.model_tag,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": request}]\n",
        "        }\n",
        "        response = requests.post(f\"{self.api_url}/chat/completions\", headers=headers, json=data)\n",
        "\n",
        "        # Log the full response for debugging\n",
        "        response_json = response.json()\n",
        "        logger.info(f\"Full API response: {response_json}\")\n",
        "\n",
        "        # Check if 'choices' key exists in the response\n",
        "        if \"choices\" in response_json and response_json[\"choices\"]:\n",
        "            return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
        "        else:\n",
        "            logger.error(f\"Request: {data}\")\n",
        "            logger.error(f\"Response: {response_json}\")\n",
        "            raise ValueError(\"The response does not contain 'choices'. Full response: \" + str(response_json))\n",
        "class Model:\n",
        "    def predict(self, promt):\n",
        "        pass\n",
        "\n",
        "class LlamaModel(Model):\n",
        "    def __init__(self, llamaApi: OpenAiLlamaApi):\n",
        "        self.api = llamaApi\n",
        "\n",
        "    def predict_raw(self, prompt):\n",
        "        return self.api.execute_request(prompt)\n",
        "\n",
        "    def predict(self, prompt):\n",
        "        generated_code = self.predict_raw(prompt)\n",
        "        return self._clean_and_correct_code(generated_code)\n",
        "\n",
        "    def _clean_and_correct_code(self, generated_code):\n",
        "        cleaned_code = generated_code.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
        "        cleaned_code_lines = [line for line in cleaned_code.split(\"\\n\") if not line.lower().startswith(\"here is the\")]\n",
        "        cleaned_code = \"\\n\".join(cleaned_code_lines)\n",
        "        return cleaned_code\n",
        "\n",
        "class PromptGenerator:\n",
        "    def __init__(self, example_script, dataset_info):\n",
        "        self.example_script = example_script\n",
        "        self.dataset_info = dataset_info\n",
        "\n",
        "    def generate(self, step: Step, model_parameters):\n",
        "        # f\"Use these predefined parameters if needed: SizeSegment={SizeSegment}, gamma={gamma}, nu={nu}, kernel='{kernel}', NC_pca={NC_pca}, Dec_levels={Dec_levels}. \"\n",
        "        parameters_str = ', '.join(f'{name}={val}' for name, val in parameters.items())\n",
        "        request = (\n",
        "            f\"Here is an example of a good step script:\\n\\n{self.example_script}\\n\\n\"\n",
        "            f\"Here is an example of a good validation script:\\n\\n{self.example_script}\\n\\n\"\n",
        "            f\"Write a Python function named 'step_{step.step_id}' for the following step: {step.desiption}. \"\n",
        "            f\"The function should take {', '.join(step.input_vars)} as input and return {', '.join(step.output_vars)}. \"\n",
        "            f\"Ensure to include necessary imports and handle edge cases. \"\n",
        "            f\"Additional information: {step.additional_info}\\n\"\n",
        "            f\"The dataset has the following columns: {self.dataset_info['columns']}. \"\n",
        "            f\"The data types are: {self.dataset_info['types']}. \"\n",
        "            f\"Here's a sample of the data: {self.dataset_info['sample_data']}. \"\n",
        "            f\"Value counts (top 5): {self.dataset_info['value_counts']}. \"\n",
        "            f\"Statistical description: {self.dataset_info['description']}. \"\n",
        "            f\"Use these predefined parameters if needed: {parameters_str}. \"\n",
        "            f\"The input 'Segments' is a list of 1D numpy arrays, each representing a segment of the signal data. \"\n",
        "            f\"Each segment should be normalized independently using sklearn's MinMaxScaler. \"\n",
        "            f\"The output 'Segments_normalized' should be a list of normalized 1D numpy arrays. \"\n",
        "            f\"Only return the function definition without any additional code or explanations.\"\n",
        "        )\n",
        "        return request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrleRHw6clay"
      },
      "source": [
        "# Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "haa1DU_Hck6A"
      },
      "outputs": [],
      "source": [
        "def get_dataset_info(df):\n",
        "    columns = df.columns.tolist()\n",
        "    types = df.dtypes.apply(lambda x: str(x)).to_dict()\n",
        "    sample_data = df.head().to_dict(orient='list')\n",
        "    value_counts = {col: df[col].value_counts().head().to_dict() for col in df.columns}\n",
        "    description = df.describe().to_dict()\n",
        "\n",
        "    dataset_info = {\n",
        "        'columns': columns,\n",
        "        'types': types,\n",
        "        'sample_data': sample_data,\n",
        "        'value_counts': value_counts,\n",
        "        'description': description\n",
        "    }\n",
        "    return dataset_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-gKchtZcs5a"
      },
      "source": [
        "# Code Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EFrQp5e-OMAD"
      },
      "outputs": [],
      "source": [
        "class CodeGenerator:\n",
        "  def generate_source(self, step, step_dependencies, parameters, additonal_lines):\n",
        "    pass\n",
        "\n",
        "class MainCodeGenerator(CodeGenerator):\n",
        "    def generate_source(self, step: Step, step_dependencies, parameters, additonal_lines=[]):\n",
        "        # TODO: implement\n",
        "        pass\n",
        "\n",
        "class ValidationCodeGenerator(CodeGenerator):\n",
        "  def generate_source(self, step: Step, step_dependencies: List[Step], parameters, additonal_lines=[]):\n",
        "      input_params = step.input_vars\n",
        "      output_params = step.output_vars\n",
        "\n",
        "      validation_code = \"import pandas as pd\\n\"\n",
        "      for dep in sorted(step_dependencies):\n",
        "          validation_code += f\"from step_{dep.step_id} import step_{dep.step_id}\\n\"\n",
        "      validation_code += f\"from step_{step.step_id} import step_{step.step_id}\\n\\n\"\n",
        "\n",
        "      validation_code += \"\\n\"\n",
        "      for name, value in parameters.items():\n",
        "          validation_code += f'{name} = {value}\\n'\n",
        "      validation_code += \"\\n\"\n",
        "\n",
        "      validation_code += \"def validate_step():\\n\"\n",
        "\n",
        "      for dep in sorted(step_dependencies):\n",
        "          dep_inputs = \", \".join(dep.input_vars)\n",
        "          dep_outputs = \", \".join(dep.output_vars)\n",
        "          validation_code += f\"    {dep_outputs} = step_{dep.step_id}({dep_inputs})\\n\"\n",
        "\n",
        "      input_values = \", \".join(input_params)\n",
        "      output_values = \", \".join(output_params)\n",
        "      validation_code += f\"    {output_values} = step_{step.step_id}({input_values})\\n\"\n",
        "      validation_code += f\"    print({output_values})\\n\"\n",
        "\n",
        "      validation_code += \"\\nif __name__ == '__main__':\\n\"\n",
        "      validation_code += \"    validate_step()\\n\"\n",
        "      return validation_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gH2E5swN7jnU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5OfrIJuczUE"
      },
      "source": [
        "# Orchestration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3ST4FyUTPYHs"
      },
      "outputs": [],
      "source": [
        "def topological_sort(steps: List[Step]) -> List[Step]:\n",
        "    used = set()\n",
        "    order = []\n",
        "    id_to_step = {step.step_id: step for step in steps}\n",
        "    def dfs(step):\n",
        "        nonlocal order\n",
        "        nonlocal used\n",
        "        nonlocal id_to_step\n",
        "        if step.step_id in used:\n",
        "            return\n",
        "        used.add(step.step_id)\n",
        "        for dep_id in step.dependencies:\n",
        "            dfs(id_to_step[dep_id])\n",
        "        order.append(step)\n",
        "    for step in steps:\n",
        "        dfs(step)\n",
        "    return order\n",
        "\n",
        "class Orchestrator:\n",
        "    MAX_RETRIES = 10\n",
        "\n",
        "    def __init__(\n",
        "          self,\n",
        "          model,\n",
        "          prompt_generator,\n",
        "          validation_generator,\n",
        "          main_generator,\n",
        "          working_dir,\n",
        "        ):\n",
        "        self.model = model\n",
        "        self.prompt_generator = prompt_generator\n",
        "        self.validation_generator = validation_generator\n",
        "        self.main_generator = main_generator\n",
        "        self.working_dir = working_dir\n",
        "\n",
        "\n",
        "    def run_steps(self, steps: List[Step], parameters):\n",
        "        os.makedirs(self.working_dir, exist_ok=True)\n",
        "\n",
        "        id_to_step = {step.step_id: step for step in steps}\n",
        "        steps_ordered = topological_sort(steps)\n",
        "\n",
        "        for step in steps_ordered:\n",
        "            try:\n",
        "                code_snippet, _ = self.generate_step_file(step, parameters)\n",
        "                dependencies = [id_to_step[step_id] for step_id in step.dependencies]\n",
        "                _, validation_filename = self.generate_validation_file(step, dependencies, parameters)\n",
        "                success, message = self.validate_unit_code(validation_filename)\n",
        "\n",
        "                for _ in range(Orchestrator.MAX_RETRIES):\n",
        "                    if success:\n",
        "                        break\n",
        "                    code_snippet, _ = self.fix_step_source(step, code_snippet, message)\n",
        "                    success, message = self.validate_unit_code(validation_filename)\n",
        "                if not success:\n",
        "                    continue\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing step {step.step_id}: {e}\\n{traceback.format_exc()}\\n\")\n",
        "                break\n",
        "            # TODO: generate main\n",
        "\n",
        "    def generate_step_file(self, step, parameters):\n",
        "        prompt = self.prompt_generator.generate(step, parameters)\n",
        "        code_snippet = self.model.predict(prompt)\n",
        "        filename = f'step_{step.step_id}.py'\n",
        "        with open(self.working_dir + '/' + filename, 'w') as f:\n",
        "            f.write(code_snippet)\n",
        "        print(f'generated step source for step {step.step_id}, filename: {filename}')\n",
        "        print(code_snippet)\n",
        "        print()\n",
        "        return code_snippet, filename\n",
        "\n",
        "    def generate_validation_file(self, step, dependencies, parameters):\n",
        "        source = self.validation_generator.generate_source(step, dependencies, parameters)\n",
        "        filename = f'validate_step_{step.step_id}.py'\n",
        "        with open(self.working_dir + '/' + filename, 'w') as f:\n",
        "            f.write(source)\n",
        "        print(f'generated validation source for step {step.step_id}, filename: {filename}')\n",
        "        print(source)\n",
        "        print()\n",
        "        return source, filename\n",
        "\n",
        "    def fix_step_source(self, step, code_snippet, error_message):\n",
        "      prompt = (\n",
        "          f\"The following code snippet encountered an error:\\n\\n{code_snippet}\\n\\n\"\n",
        "          f\"Error message:\\n{error_message}\\n\\n\"\n",
        "          f\"Please fix the code snippet to resolve the error without providing any explanations or comments.\"\n",
        "      )\n",
        "      source = self.model.predict(prompt)\n",
        "      filename = f'step_{step.step_id}.py'\n",
        "      with open(self.working_dir + '/' + filename, 'w') as f:\n",
        "          f.write(source)\n",
        "      print(f'fixing step source for step {step.step_id}, filename: {filename}')\n",
        "      print(source)\n",
        "      print()\n",
        "      return source, filename\n",
        "\n",
        "    def validate_unit_code(self, filename):\n",
        "        try:\n",
        "            work_path = os.path.realpath(self.working_dir)\n",
        "            print(f'running {filename} in {work_path}')\n",
        "            result = subprocess.run(\n",
        "                [\"python\", filename],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                cwd=work_path\n",
        "            )\n",
        "            print(f'exit_code = {result.returncode}')\n",
        "            if result.returncode != 0:\n",
        "                raise Exception(result.stderr)\n",
        "            return True, result.stdout\n",
        "        except Exception as e:\n",
        "            return False, str(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHPtwgq9dA3g"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mf6QhtuvZ1fe"
      },
      "outputs": [],
      "source": [
        "EXAMPLE_STEP_SCRIPT = \"\"\"\n",
        "import pandas as pd\n",
        "import pywt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def step_40(Segments_normalized, Dec_levels):\n",
        "    Features = []\n",
        "    for segment in Segments_normalized:\n",
        "        coeffs = pywt.wavedec(segment, 'db4', level=Dec_levels)\n",
        "        features = [coefficient.mean() for coefficient in coeffs]\n",
        "        Features.append(features)\n",
        "    return StandardScaler().fit_transform(Features)\n",
        "\"\"\"\n",
        "\n",
        "EXAMPLE_VALIDATION_SCRIPT = \"\"\"\n",
        "import pandas as pd\n",
        "from step_10 import step_10\n",
        "from step_20 import step_20\n",
        "from step_30 import step_30\n",
        "from step_40 import step_40\n",
        "\n",
        "def validate_step():\n",
        "    csv_path = '/path/to/your/csv/file.csv'\n",
        "    raw_data = step_10(csv_path)\n",
        "    Segments = step_20(raw_data, SizeSegment=512)\n",
        "    Segments_normalized = step_30(Segments)\n",
        "    Features = step_40(Segments_normalized, Dec_levels=5)\n",
        "    print(Features)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    validate_step()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Z_yBFmgkdliy"
      },
      "outputs": [],
      "source": [
        "steps = [\n",
        "    Step(\n",
        "        step_id=\"10\",\n",
        "        description=\"Import raw data from CSV and segment it\",\n",
        "        dependencies=[],\n",
        "        input_vars=[\"csv_path\", \"SizeSegment\"],\n",
        "        output_vars=[\"Segments\"],\n",
        "        additional_info=\"Use pandas to read the CSV and create segments of size SizeSegment.\"\n",
        "    ),\n",
        "    Step(\n",
        "        step_id=\"20\",\n",
        "        description=\"Normalize the segmented data using MinMaxScaler\",\n",
        "        dependencies=[\"10\"],\n",
        "        input_vars=[\"Segments\"],\n",
        "        output_vars=[\"Segments_normalized\"],\n",
        "        additional_info=\"Segments is a list of 1D numpy arrays. Each segment should be normalized independently.\"\n",
        "    ),\n",
        "    Step(\n",
        "        step_id=\"30\",\n",
        "        description=\"Extract features using wavelet decomposition\",\n",
        "        dependencies=[\"20\"],\n",
        "        input_vars=[\"Segments_normalized\", \"Dec_levels\"],\n",
        "        output_vars=[\"Features\"],\n",
        "        additional_info=\"Use pywavelets (pywt) library with 'db3' wavelet and specified Dec_levels.\"\n",
        "    ),\n",
        "    Step(\n",
        "        step_id=\"40\",\n",
        "        description=\"Apply PCA for dimension reduction\",\n",
        "        dependencies=[\"30\"],\n",
        "        input_vars=[\"Features\", \"NC_pca\"],\n",
        "        output_vars=[\"PCA_Features\", \"pca\"],\n",
        "        additional_info=\"Use sklearn's PCA. Return both the transformed features and the PCA object.\"\n",
        "    ),\n",
        "    Step(step_id=\"50\",\n",
        "        description=\"Train model, evaluate, and calculate metrics\",\n",
        "        dependencies=[\"40\"],\n",
        "        input_vars=[\"PCA_Features\", \"kernel\", \"nu\", \"gamma\"],\n",
        "        output_vars=[\"FittedClassifier\", \"Prec_learn\", \"Prec_test\"],\n",
        "        additional_info=\"\"\"\n",
        "        1. Create labels: np.ones for learning data.\n",
        "        2. Split data into train and test sets (80% train, 20% test).\n",
        "        3. Create and fit a One-Class SVM classifier using sklearn.\n",
        "        4. Predict labels for training data.\n",
        "        5. Calculate error rate for training data.\n",
        "        6. Predict labels for test data (assume all test data as anomaly, i.e., -1).\n",
        "        7. Calculate error rate for test data.\n",
        "        8. Calculate precision as 1 - error_rate for both training and test.\n",
        "        Return the fitted classifier and both precision values.\n",
        "        \"\"\"\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "x78NbYf5gVBc"
      },
      "outputs": [],
      "source": [
        "with open('env.json', 'r') as f:\n",
        "  credentials_dict = json.load(f)\n",
        "\n",
        "API_URL = \"https://openrouter.ai/api/v1\"\n",
        "API_KEY = credentials_dict[\"OPENROUTER_API_KEY\"]\n",
        "MODEL_TAG = \"meta-llama/llama-3-70b-instruct\"\n",
        "\n",
        "df = pd.read_csv(\n",
        "    '/Users/ilya/Desktop/GitHub_Repositories/Thesis/datasets/complicated_case/learning-file_1.csv')\n",
        "dataset_info = get_dataset_info(df)\n",
        "\n",
        "# Predefined parameters\n",
        "raw_data = pd.read_csv(\n",
        "    \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/datasets/complicated_case/learning-file_1.csv\")\n",
        "# Assume raw_data is a pandas DataFrame with 'timestamp' and 'signal' columns\n",
        "signal_data = raw_data['signal'].values\n",
        "\n",
        "# Adjust based on data size\n",
        "SizeSegment = min(512, len(signal_data) // 100)\n",
        "gamma = 'scale'  # Let sklearn choose an appropriate scale\n",
        "nu = 0.1  # This might need domain knowledge to set appropriately\n",
        "kernel = \"rbf\"  # This is often a good default\n",
        "\n",
        "# PCA\n",
        "# We'll use the signal data for PCA parameter calculation\n",
        "pca = PCA().fit(signal_data.reshape(-1, 1))\n",
        "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
        "NC_pca = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
        "\n",
        "Dec_levels = int(np.log2(SizeSegment)) - 3  # Adjust based on segment size\n",
        "csv_path = '/Users/ilya/Desktop/GitHub_Repositories/Thesis/datasets/complicated_case/learning-file_1.csv'\n",
        "\n",
        "parameters = {\n",
        "    'csv_path': f\"'{csv_path}'\",\n",
        "    \"SizeSegment\": f\"{SizeSegment}\",\n",
        "    \"gamma\": f\"'{gamma}'\",\n",
        "    \"nu\": f\"{nu}\",\n",
        "    \"kernel\" : f\"'{kernel}'\",\n",
        "    \"NC_pca\": f\"{NC_pca}\",\n",
        "    \"Dec_levels\": f\"{Dec_levels}\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9ghgzcPWdyz-"
      },
      "outputs": [],
      "source": [
        "llama_api = OpenAiLlamaApi(API_URL, API_KEY, MODEL_TAG)\n",
        "model = LlamaModel(llama_api)\n",
        "prompt_generator = PromptGenerator(EXAMPLE_STEP_SCRIPT, dataset_info)\n",
        "validation_code_genrator = ValidationCodeGenerator()\n",
        "main_code_generator = MainCodeGenerator()\n",
        "\n",
        "orchestrator = Orchestrator(\n",
        "    model,\n",
        "    prompt_generator,\n",
        "    validation_code_genrator,\n",
        "    main_code_generator,\n",
        "    'out'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Gg2bS3gXli",
        "outputId": "cf235184-fee7-41ba-d4c0-a703795dcaa6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-07-31 19:56:35.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_request\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mFull API response: {'id': 'gen-44YNUpF2UuTf64cN3LYOcHRcBQVn', 'model': 'meta-llama/llama-3-70b-instruct', 'object': 'chat.completion', 'created': 1722441387, 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Here is the Python function named 'step_10':\\n\\n```\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\ndef step_10(csv_path, SizeSegment):\\n    data = pd.read_csv(csv_path)\\n    signal = data['signal'].values\\n    Segments = [signal[i:i+SizeSegment] for i in range(0, len(signal), SizeSegment)]\\n    Segments_normalized = [MinMaxScaler().fit_transform(segment.reshape(-1, 1)).flatten() for segment in Segments]\\n    return Segments_normalized\\n```\"}, 'finish_reason': 'stop', 'logprobs': None}], 'usage': {'prompt_tokens': 721, 'completion_tokens': 118, 'total_tokens': 839}}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated step source for step 10, filename: step_10.py\n",
            "\n",
            "\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.preprocessing import MinMaxScaler\n",
            "\n",
            "def step_10(csv_path, SizeSegment):\n",
            "    data = pd.read_csv(csv_path)\n",
            "    signal = data['signal'].values\n",
            "    Segments = [signal[i:i+SizeSegment] for i in range(0, len(signal), SizeSegment)]\n",
            "    Segments_normalized = [MinMaxScaler().fit_transform(segment.reshape(-1, 1)).flatten() for segment in Segments]\n",
            "    return Segments_normalized\n",
            "\n",
            "generated validation source for step 10, filename: validate_step_10.py\n",
            "import pandas as pd\n",
            "from step_10 import step_10\n",
            "\n",
            "\n",
            "csv_path = '/Users/ilya/Desktop/GitHub_Repositories/Thesis/datasets/complicated_case/learning-file_1.csv'\n",
            "SizeSegment = 307\n",
            "gamma = 'scale'\n",
            "nu = 0.1\n",
            "kernel = 'rbf'\n",
            "NC_pca = 1\n",
            "Dec_levels = 5\n",
            "\n",
            "def validate_step():\n",
            "    Segments = step_10(csv_path, SizeSegment)\n",
            "    print(Segments)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    validate_step()\n",
            "\n",
            "\n",
            "running validate_step_10.py in /Users/ilya/Desktop/CodeGeneration-main/Jupyter_notebook/out\n",
            "exit_code = 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-07-31 19:56:40.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_request\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mFull API response: {'id': 'gen-KIZizbFRqPuPhsxYQpAHVVMzAR7v', 'model': 'meta-llama/llama-3-70b-instruct', 'object': 'chat.completion', 'created': 1722441397, 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Here is the Python function `step_20` for normalizing the segmented data using MinMaxScaler:\\n```\\nimport numpy as np\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\ndef step_20(Segments):\\n    Segments_normalized = []\\n    for segment in Segments:\\n        scaler = MinMaxScaler()\\n        normalized_segment = scaler.fit_transform(segment.reshape(-1, 1)).reshape(-1)\\n        Segments_normalized.append(normalized_segment)\\n    return Segments_normalized\\n```'}, 'finish_reason': 'stop', 'logprobs': {'tokens': None, 'token_logprobs': None, 'top_logprobs': None, 'text_offset': None}}], 'usage': {'prompt_tokens': 724, 'completion_tokens': 100, 'total_tokens': 824}}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated step source for step 20, filename: step_20.py\n",
            "\n",
            "import numpy as np\n",
            "from sklearn.preprocessing import MinMaxScaler\n",
            "\n",
            "def step_20(Segments):\n",
            "    Segments_normalized = []\n",
            "    for segment in Segments:\n",
            "        scaler = MinMaxScaler()\n",
            "        normalized_segment = scaler.fit_transform(segment.reshape(-1, 1)).reshape(-1)\n",
            "        Segments_normalized.append(normalized_segment)\n",
            "    return Segments_normalized\n",
            "\n",
            "generated validation source for step 20, filename: validate_step_20.py\n",
            "import pandas as pd\n",
            "from step_10 import step_10\n",
            "from step_20 import step_20\n",
            "\n",
            "\n",
            "csv_path = '/Users/ilya/Desktop/GitHub_Repositories/Thesis/datasets/complicated_case/learning-file_1.csv'\n",
            "SizeSegment = 307\n",
            "gamma = 'scale'\n",
            "nu = 0.1\n",
            "kernel = 'rbf'\n",
            "NC_pca = 1\n",
            "Dec_levels = 5\n",
            "\n",
            "def validate_step():\n",
            "    Segments = step_10(csv_path, SizeSegment)\n",
            "    Segments_normalized = step_20(Segments)\n",
            "    print(Segments_normalized)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    validate_step()\n",
            "\n",
            "\n",
            "running validate_step_20.py in /Users/ilya/Desktop/CodeGeneration-main/Jupyter_notebook/out\n",
            "exit_code = 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-07-31 19:56:43.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_request\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mFull API response: {'id': 'gen-SlD4ChYbWPyMhq5B1kua1PbE73oE', 'model': 'meta-llama/llama-3-70b-instruct', 'object': 'chat.completion', 'created': 1722441402, 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Here is the Python function `step_30`:\\n```\\nimport pandas as pd\\nimport pywt\\n\\ndef step_30(Segments_normalized, Dec_levels):\\n    Features = []\\n    for segment in Segments_normalized:\\n        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\\n        features = [coefficient.mean() for coefficient in coeffs]\\n        Features.append(features)\\n    return Features\\n```\"}, 'finish_reason': 'eos', 'logprobs': None}], 'usage': {'prompt_tokens': 727, 'completion_tokens': 90, 'total_tokens': 817}}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated step source for step 30, filename: step_30.py\n",
            "\n",
            "import pandas as pd\n",
            "import pywt\n",
            "\n",
            "def step_30(Segments_normalized, Dec_levels):\n",
            "    Features = []\n",
            "    for segment in Segments_normalized:\n",
            "        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\n",
            "        features = [coefficient.mean() for coefficient in coeffs]\n",
            "        Features.append(features)\n",
            "    return Features\n",
            "\n",
            "generated validation source for step 30, filename: validate_step_30.py\n",
            "import pandas as pd\n",
            "from step_20 import step_20\n",
            "from step_30 import step_30\n",
            "\n",
            "\n",
            "csv_path = '/Users/ilya/Desktop/GitHub_Repositories/Thesis/datasets/complicated_case/learning-file_1.csv'\n",
            "SizeSegment = 307\n",
            "gamma = 'scale'\n",
            "nu = 0.1\n",
            "kernel = 'rbf'\n",
            "NC_pca = 1\n",
            "Dec_levels = 5\n",
            "\n",
            "def validate_step():\n",
            "    Segments_normalized = step_20(Segments)\n",
            "    Features = step_30(Segments_normalized, Dec_levels)\n",
            "    print(Features)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    validate_step()\n",
            "\n",
            "\n",
            "running validate_step_30.py in /Users/ilya/Desktop/CodeGeneration-main/Jupyter_notebook/out\n",
            "exit_code = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-07-31 19:56:53.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_request\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mFull API response: {'id': 'gen-HtqfdXVatI9kw2BegEfXRon9pPQW', 'model': 'meta-llama/llama-3-70b-instruct', 'object': 'chat.completion', 'created': 1722441405, 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Here is the fixed code snippet:\\n\\n```\\nimport pandas as pd\\nimport pywt\\n\\ndef step_20(Segments):\\n    # implementation of step_20 function\\n    pass\\n\\ndef step_30(Segments_normalized, Dec_levels):\\n    Features = []\\n    for segment in Segments_normalized:\\n        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\\n        features = [coefficient.mean() for coefficient in coeffs]\\n        Features.append(features)\\n    return Features\\n\\nSegments = [...]  # define Segments here\\nSegments_normalized = step_20(Segments)\\nDec_levels =...  # define Dec_levels here\\nFeatures = step_30(Segments_normalized, Dec_levels)\\n```\"}, 'finish_reason': 'stop', 'logprobs': None}], 'usage': {'prompt_tokens': 211, 'completion_tokens': 150, 'total_tokens': 361}}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fixing step source for step 30, filename: step_30.py\n",
            "\n",
            "\n",
            "import pandas as pd\n",
            "import pywt\n",
            "\n",
            "def step_20(Segments):\n",
            "    # implementation of step_20 function\n",
            "    pass\n",
            "\n",
            "def step_30(Segments_normalized, Dec_levels):\n",
            "    Features = []\n",
            "    for segment in Segments_normalized:\n",
            "        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\n",
            "        features = [coefficient.mean() for coefficient in coeffs]\n",
            "        Features.append(features)\n",
            "    return Features\n",
            "\n",
            "Segments = [...]  # define Segments here\n",
            "Segments_normalized = step_20(Segments)\n",
            "Dec_levels =...  # define Dec_levels here\n",
            "Features = step_30(Segments_normalized, Dec_levels)\n",
            "\n",
            "running validate_step_30.py in /Users/ilya/Desktop/CodeGeneration-main/Jupyter_notebook/out\n",
            "exit_code = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-07-31 19:57:01.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_request\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mFull API response: {'id': 'gen-4T8FgpmkZAErw7vfO6IK2UGop3QT', 'model': 'meta-llama/llama-3-70b-instruct', 'object': 'chat.completion', 'created': 1722441415, 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Here is the corrected code snippet:\\n\\n```\\nimport pandas as pd\\nimport pywt\\n\\ndef step_20(Segments):\\n    return Segments  # implementation of step_20 function\\n\\ndef step_30(Segments_normalized, Dec_levels):\\n    Features = []\\n    for segment in Segments_normalized:\\n        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\\n        features = [coefficient.mean() for coefficient in coeffs]\\n        Features.append(features)\\n    return Features\\n\\nSegments = [...]  # define Segments here\\nSegments_normalized = step_20(Segments)\\nDec_levels =...  # define Dec_levels here\\nFeatures = step_30(Segments_normalized, Dec_levels)\\n```\"}, 'finish_reason': 'stop', 'logprobs': None}], 'usage': {'prompt_tokens': 322, 'completion_tokens': 151, 'total_tokens': 473}}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fixing step source for step 30, filename: step_30.py\n",
            "\n",
            "\n",
            "import pandas as pd\n",
            "import pywt\n",
            "\n",
            "def step_20(Segments):\n",
            "    return Segments  # implementation of step_20 function\n",
            "\n",
            "def step_30(Segments_normalized, Dec_levels):\n",
            "    Features = []\n",
            "    for segment in Segments_normalized:\n",
            "        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\n",
            "        features = [coefficient.mean() for coefficient in coeffs]\n",
            "        Features.append(features)\n",
            "    return Features\n",
            "\n",
            "Segments = [...]  # define Segments here\n",
            "Segments_normalized = step_20(Segments)\n",
            "Dec_levels =...  # define Dec_levels here\n",
            "Features = step_30(Segments_normalized, Dec_levels)\n",
            "\n",
            "running validate_step_30.py in /Users/ilya/Desktop/CodeGeneration-main/Jupyter_notebook/out\n",
            "exit_code = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-07-31 19:57:08.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_request\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mFull API response: {'id': 'gen-MVQ6JgpZR9wMrywpuZzKX4jkFy9X', 'model': 'meta-llama/llama-3-70b-instruct', 'object': 'chat.completion', 'created': 1722441423, 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Here is the corrected code snippet:\\n\\n```\\nimport pandas as pd\\nimport pywt\\n\\ndef step_20(Segments):\\n    return Segments  # implementation of step_20 function\\n\\ndef step_30(Segments_normalized, Dec_levels):\\n    Features = []\\n    for segment in Segments_normalized:\\n        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\\n        features = [coefficient.mean() for coefficient in coeffs]\\n        Features.append(features)\\n    return Features\\n\\nSegments = [1, 2, 3, 4, 5]  # define Segments here\\nDec_levels = 2  # define Dec_levels here\\nSegments_normalized = step_20(Segments)\\nFeatures = step_30(Segments_normalized, Dec_levels)\\n```\"}, 'finish_reason': 'stop', 'logprobs': {'tokens': None, 'token_logprobs': None, 'top_logprobs': None, 'text_offset': None}}], 'usage': {'prompt_tokens': 347, 'completion_tokens': 166, 'total_tokens': 513}}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fixing step source for step 30, filename: step_30.py\n",
            "\n",
            "\n",
            "import pandas as pd\n",
            "import pywt\n",
            "\n",
            "def step_20(Segments):\n",
            "    return Segments  # implementation of step_20 function\n",
            "\n",
            "def step_30(Segments_normalized, Dec_levels):\n",
            "    Features = []\n",
            "    for segment in Segments_normalized:\n",
            "        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\n",
            "        features = [coefficient.mean() for coefficient in coeffs]\n",
            "        Features.append(features)\n",
            "    return Features\n",
            "\n",
            "Segments = [1, 2, 3, 4, 5]  # define Segments here\n",
            "Dec_levels = 2  # define Dec_levels here\n",
            "Segments_normalized = step_20(Segments)\n",
            "Features = step_30(Segments_normalized, Dec_levels)\n",
            "\n",
            "running validate_step_30.py in /Users/ilya/Desktop/CodeGeneration-main/Jupyter_notebook/out\n",
            "exit_code = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-07-31 19:57:15.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute_request\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mFull API response: {'id': 'gen-Fy8H72jv5o4IsUIIecv5nZaVqEED', 'model': 'meta-llama/llama-3-70b-instruct', 'object': 'chat.completion', 'created': 1722441430, 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Here is the corrected code snippet:\\n\\n```\\nimport pandas as pd\\nimport pywt\\nimport numpy as np\\n\\ndef step_20(Segments):\\n    return np.array(Segments)  # implementation of step_20 function\\n\\ndef step_30(Segments_normalized, Dec_levels):\\n    Features = []\\n    for segment in Segments_normalized:\\n        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\\n        features = [coefficient.mean() for coefficient in coeffs]\\n        Features.append(features)\\n    return Features\\n\\nSegments = [1, 2, 3, 4, 5]  # define Segments here\\nDec_levels = 2  # define Dec_levels here\\nSegments_normalized = step_20(Segments)\\nFeatures = step_30(Segments_normalized, Dec_levels)\\n```\"}, 'finish_reason': 'stop', 'logprobs': {'tokens': None, 'token_logprobs': None, 'top_logprobs': None, 'text_offset': None}}], 'usage': {'prompt_tokens': 473, 'completion_tokens': 175, 'total_tokens': 648}}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fixing step source for step 30, filename: step_30.py\n",
            "\n",
            "\n",
            "import pandas as pd\n",
            "import pywt\n",
            "import numpy as np\n",
            "\n",
            "def step_20(Segments):\n",
            "    return np.array(Segments)  # implementation of step_20 function\n",
            "\n",
            "def step_30(Segments_normalized, Dec_levels):\n",
            "    Features = []\n",
            "    for segment in Segments_normalized:\n",
            "        coeffs = pywt.wavedec(segment, 'db3', level=int(Dec_levels))\n",
            "        features = [coefficient.mean() for coefficient in coeffs]\n",
            "        Features.append(features)\n",
            "    return Features\n",
            "\n",
            "Segments = [1, 2, 3, 4, 5]  # define Segments here\n",
            "Dec_levels = 2  # define Dec_levels here\n",
            "Segments_normalized = step_20(Segments)\n",
            "Features = step_30(Segments_normalized, Dec_levels)\n",
            "\n",
            "running validate_step_30.py in /Users/ilya/Desktop/CodeGeneration-main/Jupyter_notebook/out\n",
            "exit_code = 1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43morchestrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[24], line 53\u001b[0m, in \u001b[0;36mOrchestrator.run_steps\u001b[0;34m(self, steps, parameters)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     code_snippet, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfix_step_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_snippet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     success, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_unit_code(validation_filename)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n",
            "Cell \u001b[0;32mIn[24], line 89\u001b[0m, in \u001b[0;36mOrchestrator.fix_step_source\u001b[0;34m(self, step, code_snippet, error_message)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfix_step_source\u001b[39m(\u001b[38;5;28mself\u001b[39m, step, code_snippet, error_message):\n\u001b[1;32m     84\u001b[0m   prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     85\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following code snippet encountered an error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcode_snippet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError message:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease fix the code snippet to resolve the error without providing any explanations or comments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m   )\n\u001b[0;32m---> 89\u001b[0m   source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m   filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mstep_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     91\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworking_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "Cell \u001b[0;32mIn[21], line 41\u001b[0m, in \u001b[0;36mLlamaModel.predict\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt):\n\u001b[0;32m---> 41\u001b[0m     generated_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_and_correct_code(generated_code)\n",
            "Cell \u001b[0;32mIn[21], line 38\u001b[0m, in \u001b[0;36mLlamaModel.predict_raw\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[21], line 16\u001b[0m, in \u001b[0;36mOpenAiLlamaApi.execute_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m      8\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_tag,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: request}]\n\u001b[1;32m     15\u001b[0m }\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Log the full response for debugging\u001b[39;00m\n\u001b[1;32m     19\u001b[0m response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/connection.py:653\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[1;32m    651\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 653\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# Forwarding proxies can never have a verified target since\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# the proxy is the one doing the verification. Should instead\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# use a CONNECT tunnel in order to verify the target.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# See: https://github.com/urllib3/urllib3/issues/3267.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/connection.py:806\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[1;32m    804\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[0;32m--> 806\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/util/ssl_.py:465\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:  \u001b[38;5;66;03m# Defensive: in CI, we always have set_alpn_protocols\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/site-packages/urllib3/util/ssl_.py:509\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    506\u001b[0m     SSLTransport\u001b[38;5;241m.\u001b[39m_validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   1102\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.10/ssl.py:1375\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[1;32m   1374\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1375\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "orchestrator.run_steps(steps, parameters)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
