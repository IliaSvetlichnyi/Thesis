{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate code snippets without comments and ensure they are ready to execute.\"),\n",
    "    human_prompt\n",
    "])\n",
    "# Ensure reproducibility by setting a seed\n",
    "model = Ollama(model=\"llama3\", temperature=0)\n",
    "\n",
    "# Function to generate code with LLM\n",
    "def generate_code(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_and_correct_code(generated_code, csv_path):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    if \"Here is the code snippet:\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\n",
    "            \"Here is the code snippet:\")[1].strip()\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    corrected_code = cleaned_code.replace(\"{csv_path}\", f\"'{csv_path}'\")\n",
    "    return corrected_code\n",
    "\n",
    "\n",
    "# Generate initial code\n",
    "request = \"Write me a code for reading a CSV file and printing the first five rows. Use placeholders like {csv_path} for dynamic inputs.\"\n",
    "generated_code = generate_code(request)\n",
    "csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/Iris.csv\"\n",
    "corrected_code = clean_and_correct_code(generated_code, csv_path)\n",
    "\n",
    "# Print cleaned and corrected code for debugging\n",
    "print(\"Corrected code:\")\n",
    "print(corrected_code)\n",
    "\n",
    "# Save the generated code to a .py file\n",
    "code_filename = \"generated_code.py\"\n",
    "with open(code_filename, \"w\") as file:\n",
    "    file.write(corrected_code)\n",
    "\n",
    "print(f\"Generated code saved to {code_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected code:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "csv_path = '/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/Iris.csv'\n",
      "df = pd.read_csv(csv_path)\n",
      "\n",
      "for col in df.columns:\n",
      "    if df[col].isnull().any():\n",
      "        df[col].fillna(df[col].mean(), inplace=True)\n",
      "\n",
      "print(df.head(5))\n",
      "Generated code saved to generated_code.py\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate only the code snippets without any explanations or comments.\"),\n",
    "    human_prompt\n",
    "])\n",
    "# Ensure reproducibility by setting a seed\n",
    "model = Ollama(model=\"llama3\", temperature=0)\n",
    "\n",
    "# Function to generate code with LLM\n",
    "\n",
    "\n",
    "def generate_code(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_and_correct_code(generated_code, csv_path):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    if \"Here is the code snippet:\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\n",
    "            \"Here is the code snippet:\")[1].strip()\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    corrected_code = cleaned_code.replace(\"{csv_path}\", f\"{csv_path}\")\n",
    "    return corrected_code\n",
    "\n",
    "\n",
    "# Generate initial code\n",
    "request = \"Write a Python code for reading a CSV file, filling missing values with the mean of their respective columns, and printing the first five rows. Use placeholders like {csv_path} for dynamic inputs. Only return the code without any explanations.\"\n",
    "generated_code = generate_code(request)\n",
    "csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/Iris.csv\"\n",
    "corrected_code = clean_and_correct_code(generated_code, f\"{csv_path}\")\n",
    "\n",
    "# Print cleaned and corrected code for debugging\n",
    "print(\"Corrected code:\")\n",
    "print(corrected_code)\n",
    "\n",
    "# Save the generated code to a .py file\n",
    "code_filename = \"generated_code.py\"\n",
    "with open(code_filename, \"w\") as file:\n",
    "    file.write(corrected_code)\n",
    "\n",
    "print(f\"Generated code saved to {code_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
