{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate only the code snippets without any explanations or comments.\"),\n",
    "    human_prompt\n",
    "])\n",
    "\n",
    "# Initialize the Hugging Face model\n",
    "model_id = \"Qwen/CodeQwen1.5-7B-Chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "pipe = pipeline(\"text-generation\", model=model,\n",
    "                tokenizer=tokenizer, max_new_tokens=500)\n",
    "hf_model = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen1.5-7B-Chat\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-7B-Chat\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids, max_new_tokens=512, do_sample=True)\n",
    "\n",
    "generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(\n",
    "    model_inputs.input_ids, generated_ids)]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/Iris.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"CSV file not found at path: {csv_path}\")\n",
    "\n",
    "\n",
    "def get_dataset_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df.columns.tolist()\n",
    "\n",
    "\n",
    "def generate_code(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_string()\n",
    "    response = hf_model(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "columns = get_dataset_columns(csv_path)\n",
    "columns_info = \", \".join(columns)\n",
    "\n",
    "# Provide a simpler prompt to the LLM\n",
    "simple_prompt = (\n",
    "    f\"Write a Python script to perform the following tasks using the dataset with columns: {columns_info}:\\n\"\n",
    "    \"1. Read a CSV file and load it into a pandas DataFrame.\\n\"\n",
    "    \"2. Print the first 5 rows of the DataFrame.\\n\"\n",
    "    \"Use placeholders like {csv_path} for dynamic inputs. Only return the code without any explanations.\"\n",
    ")\n",
    "\n",
    "# Generate and validate the code\n",
    "request = simple_prompt\n",
    "success = False\n",
    "while not success:\n",
    "    generated_code = generate_code(request)\n",
    "    cleaned_code = clean_code(generated_code)\n",
    "    success, output = validate_code(cleaned_code)\n",
    "    if not success:\n",
    "        print(\"Validation failed with error:\")\n",
    "        print(output)\n",
    "        # Update the request to include the error for the LLM to regenerate the code\n",
    "        request = (\n",
    "            f\"Fix the following code and its errors:\\n{cleaned_code}\\nError:\\n{output}\\n\"\n",
    "            f\"Ensure you use the correct column names from the dataset: {columns_info}.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Code validated successfully. Output:\")\n",
    "        print(output)\n",
    "\n",
    "# Save the validated code to a .py file\n",
    "simple_code_filename = \"simple_validated_code.py\"\n",
    "with open(simple_code_filename, \"w\") as file:\n",
    "    file.write(cleaned_code)\n",
    "\n",
    "print(f\"Validated code saved to {simple_code_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "# Function to generate code with LLM\n",
    "def generate_code(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_string()\n",
    "    response = hf_model(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_code(generated_code):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    cleaned_code_lines = cleaned_code.split(\"\\n\")\n",
    "    cleaned_code_lines = [\n",
    "        line for line in cleaned_code_lines if not line.lower().startswith(\"here is the\")\n",
    "    ]\n",
    "    cleaned_code = \"\\n\".join(cleaned_code_lines)\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    return cleaned_code\n",
    "\n",
    "# Function to validate the code\n",
    "\n",
    "\n",
    "def validate_code(code):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as temp_file:\n",
    "        temp_file.write(code.encode(\"utf-8\"))\n",
    "        code_filename = temp_file.name\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", code_filename], capture_output=True, text=True\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(result.stderr)\n",
    "        return True, result.stdout\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "    finally:\n",
    "        if os.path.exists(code_filename):\n",
    "            os.remove(code_filename)\n",
    "\n",
    "# Load dataset column names\n",
    "\n",
    "\n",
    "def get_dataset_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df.columns.tolist()\n",
    "\n",
    "# Main function to generate and validate code in steps\n",
    "\n",
    "\n",
    "def main():\n",
    "    csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/Iris.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"CSV file not found at path: {csv_path}\")\n",
    "\n",
    "    columns = get_dataset_columns(csv_path)\n",
    "    columns_info = \", \".join(columns)\n",
    "\n",
    "    # Provide the whole prompt to the LLM\n",
    "    whole_prompt = (\n",
    "        f\"Write a Python script to perform the following tasks using the dataset with columns: {columns_info}:\\n\"\n",
    "        \"1. Read a CSV file and load it into a pandas DataFrame.\\n\"\n",
    "        \"2. Handle missing values in the DataFrame.\\n\"\n",
    "        \"3. Encode categorical variables in the DataFrame.\\n\"\n",
    "        \"4. Split the data into training and test sets.\\n\"\n",
    "        \"5. Train a Decision Tree classifier using the training set.\\n\"\n",
    "        \"6. Evaluate the model's performance on the test set.\\n\"\n",
    "        \"Use placeholders like {csv_path} for dynamic inputs. Only return the code without any explanations.\"\n",
    "    )\n",
    "\n",
    "    # Step 1: Request the LLM to divide the prompt into steps\n",
    "    steps_prompt = \"Divide the following task into smaller steps and provide each step as a separate instruction:\\n\\n\" + whole_prompt\n",
    "    steps_response = generate_code(steps_prompt)\n",
    "    steps = [step.strip()\n",
    "             for step in steps_response.split('\\n') if step.strip()]\n",
    "\n",
    "    combined_code = \"\"\n",
    "\n",
    "    for step in steps:\n",
    "        request = f\"Write Python code to {step}. Use the path '{csv_path}' as the CSV file path.\"\n",
    "        success = False\n",
    "        while not success:\n",
    "            generated_code = generate_code(request)\n",
    "            cleaned_code = clean_code(generated_code)\n",
    "            success, output = validate_code(cleaned_code)\n",
    "            if not success:\n",
    "                print(f\"Validation failed for step '{step}' with error:\")\n",
    "                print(output)\n",
    "                # Update the request to include the error for the LLM to regenerate the code\n",
    "                request = (\n",
    "                    f\"Fix the following code and its errors:\\n{cleaned_code}\\nError:\\n{output}\\n\"\n",
    "                    f\"Ensure you use the correct column names from the dataset: {columns_info}.\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Step '{step}' validated successfully.\")\n",
    "                combined_code += cleaned_code + \"\\n\\n\"\n",
    "\n",
    "    # Final validation of the combined code\n",
    "    success, output = validate_code(combined_code)\n",
    "    if not success:\n",
    "        print(\"Final combined code validation failed with error:\")\n",
    "        print(output)\n",
    "    else:\n",
    "        print(\"Final combined code validated successfully. Output:\")\n",
    "        print(output)\n",
    "\n",
    "    # Save the validated code to a .py file\n",
    "    validated_code_filename = \"validated_combined_code.py\"\n",
    "    with open(validated_code_filename, \"w\") as file:\n",
    "        file.write(combined_code)\n",
    "\n",
    "    print(f\"Validated combined code saved to {validated_code_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate only the code snippets without any explanations or comments.\"),\n",
    "    human_prompt\n",
    "])\n",
    "\n",
    "# Initialize the Hugging Face model\n",
    "model_id = \"Qwen/CodeQwen1.5-7B-Chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "pipe = pipeline(\"text-generation\", model=model,\n",
    "                tokenizer=tokenizer)\n",
    "hf_model = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Function to generate code with LLM\n",
    "\n",
    "\n",
    "def generate_code(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_messages()\n",
    "    response = hf_model(formatted_request)\n",
    "    generated_code = response[0][\"generated_text\"]\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_code(generated_code):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    cleaned_code_lines = cleaned_code.split(\"\\n\")\n",
    "    cleaned_code_lines = [\n",
    "        line for line in cleaned_code_lines if not line.lower().startswith(\"here is the\")]\n",
    "    cleaned_code = \"\\n\".join(cleaned_code_lines)\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    return cleaned_code\n",
    "\n",
    "# Function to validate the code\n",
    "\n",
    "\n",
    "def validate_code(code):\n",
    "    code_filename = \"temp_code.py\"\n",
    "    with open(code_filename, \"w\") as file:\n",
    "        file.write(code)\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", code_filename], capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(result.stderr)\n",
    "        return True, result.stdout\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "    finally:\n",
    "        if os.path.exists(code_filename):\n",
    "            os.remove(code_filename)\n",
    "\n",
    "# Load dataset column names\n",
    "\n",
    "\n",
    "def get_dataset_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df.columns.tolist()\n",
    "\n",
    "# Main function to generate and validate code in steps\n",
    "\n",
    "\n",
    "def main():\n",
    "    csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/Iris.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"CSV file not found at path: {csv_path}\")\n",
    "\n",
    "    columns = get_dataset_columns(csv_path)\n",
    "    columns_info = \", \".join(columns)\n",
    "\n",
    "    # Provide the whole prompt to the LLM\n",
    "    whole_prompt = (\n",
    "        f\"Write a Python script to perform the following tasks using the dataset with columns: {columns_info}:\\n\"\n",
    "        \"1. Read a CSV file and load it into a pandas DataFrame.\\n\"\n",
    "        \"2. Handle missing values in the DataFrame.\\n\"\n",
    "        \"3. Encode categorical variables in the DataFrame.\\n\"\n",
    "        \"4. Split the data into training and test sets.\\n\"\n",
    "        \"5. Train a Decision Tree classifier using the training set.\\n\"\n",
    "        \"6. Evaluate the model's performance on the test set.\\n\"\n",
    "        \"Use placeholders like {csv_path} for dynamic inputs. Only return the code without any explanations.\"\n",
    "    )\n",
    "\n",
    "    # Step 1: Request the LLM to divide the prompt into steps\n",
    "    steps_prompt = \"Divide the following task into smaller steps and provide each step as a separate instruction:\\n\\n\" + whole_prompt\n",
    "    steps_response = generate_code(steps_prompt)\n",
    "    steps = [step.strip()\n",
    "             for step in steps_response.split('\\n') if step.strip()]\n",
    "\n",
    "    combined_code = \"\"\n",
    "\n",
    "    for step in steps:\n",
    "        request = f\"Write Python code to {step}. Use the path '{csv_path}' as the CSV file path.\"\n",
    "        success = False\n",
    "        while not success:\n",
    "            generated_code = generate_code(request)\n",
    "            cleaned_code = clean_code(generated_code)\n",
    "            success, output = validate_code(cleaned_code)\n",
    "            if not success:\n",
    "                print(f\"Validation failed for step '{step}' with error:\")\n",
    "                print(output)\n",
    "                # Update the request to include the error for the LLM to regenerate the code\n",
    "                request = (\n",
    "                    f\"Fix the following code and its errors:\\n{cleaned_code}\\nError:\\n{output}\\n\"\n",
    "                    f\"Ensure you use the correct column names from the dataset: {columns_info}.\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Step '{step}' validated successfully.\")\n",
    "                combined_code += cleaned_code + \"\\n\\n\"\n",
    "\n",
    "    # Final validation of the combined code\n",
    "    success, output = validate_code(combined_code)\n",
    "    if not success:\n",
    "        print(\"Final combined code validation failed with error:\")\n",
    "        print(output)\n",
    "    else:\n",
    "        print(\"Final combined code validated successfully. Output:\")\n",
    "        print(output)\n",
    "\n",
    "    # Save the validated code to a .py file\n",
    "    validated_code_filename = \"validated_combined_code.py\"\n",
    "    with open(validated_code_filename, \"w\") as file:\n",
    "        file.write(combined_code)\n",
    "\n",
    "    print(f\"Validated combined code saved to {validated_code_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
