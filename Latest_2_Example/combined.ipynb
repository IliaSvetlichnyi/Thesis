{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate only the code snippets without any explanations or comments.\"),\n",
    "    human_prompt\n",
    "])\n",
    "# Ensure reproducibility by setting a seed\n",
    "# model = Ollama(model=\"llama3\", temperature=0)\n",
    "model = Ollama(model=\"llama3\")\n",
    "\n",
    "# Function to generate code with LLM\n",
    "\n",
    "\n",
    "def generate_code(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_and_correct_code(generated_code, csv_path):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    cleaned_code_lines = cleaned_code.split(\"\\n\")\n",
    "    cleaned_code_lines = [\n",
    "        line for line in cleaned_code_lines if not line.lower().startswith(\"here is the\")]\n",
    "    cleaned_code = \"\\n\".join(cleaned_code_lines)\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    corrected_code = cleaned_code.replace(\"{csv_path}\", f\"{csv_path}\")\n",
    "    return corrected_code\n",
    "\n",
    "# Function to validate the code\n",
    "\n",
    "\n",
    "def validate_code(code_filename):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", code_filename], capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(result.stderr)\n",
    "        return True, result.stdout\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Load dataset column names\n",
    "\n",
    "\n",
    "def get_dataset_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df.columns.tolist()\n",
    "\n",
    "# Main function\n",
    "\n",
    "\n",
    "def main():\n",
    "    csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/Iris.csv\"\n",
    "    columns = get_dataset_columns(csv_path)\n",
    "    columns_info = \", \".join(columns)\n",
    "\n",
    "    request = (\n",
    "        f\"Write a Python code for reading a CSV file, handling missing values, encoding categorical variables, \"\n",
    "        f\"splitting the data into training and test sets, training a Decision Tree classifier, and evaluating the model's performance. \"\n",
    "        f\"Use placeholders like {{csv_path}} for dynamic inputs. The dataset has the following columns: {columns_info}. Only return the code without any explanations.\"\n",
    "    )\n",
    "\n",
    "    success = False\n",
    "    code_filename = \"generated_code.py\"\n",
    "\n",
    "    while not success:\n",
    "        generated_code = generate_code(request)\n",
    "        corrected_code = clean_and_correct_code(\n",
    "            generated_code, f\"'{csv_path}'\")\n",
    "\n",
    "        with open(code_filename, \"w\") as file:\n",
    "            file.write(corrected_code)\n",
    "\n",
    "        success, output = validate_code(code_filename)\n",
    "\n",
    "        if not success:\n",
    "            print(\"Code validation failed with error:\")\n",
    "            print(output)\n",
    "            # Update the request to include the error for the LLM to regenerate the code\n",
    "            request = f\"Fix the following code and its errors:\\n{corrected_code}\\nError:\\n{output}\"\n",
    "        else:\n",
    "            print(\"Code validated successfully. Output:\")\n",
    "            print(output)\n",
    "\n",
    "    # Save the validated code to a .py file\n",
    "    validated_code_filename = \"validated_generated_code.py\"\n",
    "    with open(validated_code_filename, \"w\") as file:\n",
    "        file.write(corrected_code)\n",
    "\n",
    "    print(f\"Validated code saved to {validated_code_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code saved to generated_code.py\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate only the code snippets without any explanations or comments.\"),\n",
    "    human_prompt\n",
    "])\n",
    "# Ensure reproducibility by setting a seed\n",
    "model = Ollama(model=\"llama3\")\n",
    "\n",
    "# Function to generate code with LLM\n",
    "\n",
    "\n",
    "def generate_code(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_and_correct_code(generated_code, csv_path):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    cleaned_code_lines = cleaned_code.split(\"\\n\")\n",
    "    cleaned_code_lines = [\n",
    "        line for line in cleaned_code_lines if not line.lower().startswith(\"here is the\")]\n",
    "    cleaned_code = \"\\n\".join(cleaned_code_lines)\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    corrected_code = cleaned_code.replace(\"{csv_path}\", f\"{csv_path}\")\n",
    "    return corrected_code\n",
    "\n",
    "# Load dataset column names\n",
    "\n",
    "\n",
    "def get_dataset_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df.columns.tolist()\n",
    "\n",
    "# Main function for Part 1\n",
    "\n",
    "\n",
    "def main_part1():\n",
    "    csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/insurance.csv\"\n",
    "    columns = get_dataset_columns(csv_path)\n",
    "    columns_info = \", \".join(columns)\n",
    "\n",
    "    request = (\n",
    "        f\"Write a Python code for reading a CSV file, handling missing values, encoding categorical variables, \"\n",
    "        f\"splitting the data into training and test sets, training a Decision Tree classifier, and evaluating the model's performance. \"\n",
    "        f\"Use placeholders like {{csv_path}} for dynamic inputs. The dataset has the following columns: {columns_info}. Only return the code without any explanations.\"\n",
    "    )\n",
    "\n",
    "    generated_code = generate_code(request)\n",
    "    corrected_code = clean_and_correct_code(generated_code, f\"'{csv_path}'\")\n",
    "\n",
    "    code_filename = \"generated_code.py\"\n",
    "    with open(code_filename, \"w\") as file:\n",
    "        file.write(corrected_code)\n",
    "\n",
    "    print(f\"Generated code saved to {code_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_part1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code validation failed with error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Latest_2/generated_code.py\", line 24, in <module>\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 1009, in fit\n",
      "    super()._fit(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 294, in _fit\n",
      "    check_classification_targets(y)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/utils/multiclass.py\", line 221, in check_classification_targets\n",
      "    raise ValueError(\n",
      "ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Function to validate the code\n",
    "\n",
    "\n",
    "def validate_code(code_filename):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", code_filename], capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(result.stderr)\n",
    "        return True, result.stdout\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Main function for Part 2\n",
    "\n",
    "\n",
    "def main_part2():\n",
    "    code_filename = \"generated_code.py\"\n",
    "    success, output = validate_code(code_filename)\n",
    "\n",
    "    if not success:\n",
    "        print(\"Code validation failed with error:\")\n",
    "        print(output)\n",
    "    else:\n",
    "        print(\"Code validated successfully. Output:\")\n",
    "        print(output)\n",
    "\n",
    "    return success, output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success, output = main_part2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code validation failed with error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Latest_2/generated_code.py\", line 24, in <module>\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 1009, in fit\n",
      "    super()._fit(\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 294, in _fit\n",
      "    check_classification_targets(y)\n",
      "  File \"/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/utils/multiclass.py\", line 221, in check_classification_targets\n",
      "    raise ValueError(\n",
      "ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
      "\n",
      "Validated code saved to validated_generated_code.py\n"
     ]
    }
   ],
   "source": [
    "# Main function for Part 3\n",
    "def main_part3():\n",
    "    csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/insurance.csv\"\n",
    "    with open(\"generated_code.py\", \"r\") as file:\n",
    "        initial_code = file.read()\n",
    "\n",
    "    success, output = main_part2()\n",
    "\n",
    "    if not success:\n",
    "        request = f\"Fix the following code and its errors:\\n{initial_code}\\nError:\\n{output}\"\n",
    "        generated_code = generate_code(request)\n",
    "        corrected_code = clean_and_correct_code(\n",
    "            generated_code, f\"'{csv_path}'\")\n",
    "\n",
    "        validated_code_filename = \"validated_generated_code.py\"\n",
    "        with open(validated_code_filename, \"w\") as file:\n",
    "            file.write(corrected_code)\n",
    "\n",
    "        print(f\"Validated code saved to {validated_code_filename}\")\n",
    "    else:\n",
    "        print(\"No need to fix the code, it runs successfully.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_part3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
