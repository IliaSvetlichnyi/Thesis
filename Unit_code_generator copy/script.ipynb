{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation failed for the script.\n",
      "Error:   File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator copy/script.py\", line 120\n",
      "    A data scientist's playground!\n",
      "                    ^\n",
      "SyntaxError: unterminated string literal (detected at line 120)\n",
      "\n",
      "Validation failed for the script.\n",
      "Error:   File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator copy/script.py\", line 1\n",
      "    System: You are a highly skilled data scientist with 20 years of experience specializing in insurance-related projects.\n",
      "                ^^^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "Validation failed for the script.\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator copy/script.py\", line 2, in <module>\n",
      "    from sklearn.ensemble import RandomForestRegressor, DecisionTreeRegressor\n",
      "ImportError: cannot import name 'DecisionTreeRegressor' from 'sklearn.ensemble' (/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/ensemble/__init__.py)\n",
      "\n",
      "Validation failed for the script.\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator copy/script.py\", line 3, in <module>\n",
      "    from sklearn.ensemble import RandomForestRegressor, SVR\n",
      "ImportError: cannot import name 'SVR' from 'sklearn.ensemble' (/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/ensemble/__init__.py)\n",
      "\n",
      "Validation failed for the script.\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator copy/script.py\", line 1, in <module>\n",
      "    from sklearn.ensemble import RandomForestRegressor, SVRegreessor\n",
      "ImportError: cannot import name 'SVRegreessor' from 'sklearn.ensemble' (/Users/ilya/miniconda3/envs/thesis/lib/python3.10/site-packages/sklearn/ensemble/__init__.py)\n",
      "\n",
      "Validation failed for the script.\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/Users/ilya/Desktop/GitHub_Repositories/Thesis/Unit_code_generator copy/script.py\", line 4, in <module>\n",
      "    'linear_regression': LinearRegression(),\n",
      "NameError: name 'LinearRegression' is not defined\n",
      "\n",
      "Script executed successfully.\n",
      "Documentation saved to documentation.txt\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the workflow steps with assigned numbers\n",
    "workflow_steps = {\n",
    "    11: \"Load the CSV file into a suitable format (e.g., DataFrame)\",\n",
    "    21: \"Examine the structure and characteristics of the data\",\n",
    "    22: \"Identify missing values, data types, and statistical summary\",\n",
    "    23: \"Visualize the data using charts, graphs, or plots\",\n",
    "    24: \"Gain insights and formulate hypotheses\",\n",
    "    31: \"Handle missing values (remove or impute)\",\n",
    "    32: \"Convert categorical variables to numerical representations\",\n",
    "    33: \"Perform feature scaling or normalization\",\n",
    "    34: \"Encode categorical variables (one-hot encoding, label encoding, etc.)\",\n",
    "    35: \"Split the data into training and testing sets\",\n",
    "    41: \"Create new features based on domain knowledge or data insights\",\n",
    "    42: \"Combine or transform existing features\",\n",
    "    43: \"Perform feature selection to identify relevant features\",\n",
    "    51: \"Choose appropriate machine learning algorithms based on the problem type. (don't compare differnet ones, just choose one)\",\n",
    "    52: \"Define the model architecture and hyperparameters\",\n",
    "    53: \"Train the selected model on the training data\",\n",
    "    54: \"Utilize techniques like cross-validation for model evaluation\",\n",
    "    61: \"Evaluate the trained model's performance on the testing data\",\n",
    "    62: \"Calculate evaluation metrics (e.g., accuracy, precision, recall, F1-score)\",\n",
    "    63: \"Visualize the model's performance using confusion matrix, ROC curve, etc.\",\n",
    "    64: \"Fine-tune the model if necessary\",\n",
    "    71: \"Analyze the model's coefficients or feature importances\",\n",
    "    72: \"Visualize the model's decision boundaries or learned patterns\",\n",
    "    73: \"Interpret the model's predictions and explain its behavior\",\n",
    "    81: \"Generate unit code documentation during the code generation process\",\n",
    "    82: \"Execute the combined code and capture relevant outputs and insights\",\n",
    "    83: \"Create a comprehensive documentation for the entire workflow, including project overview, dataset details, selected steps, results, and interpretations\",\n",
    "    84: \"Present the documentation to users for understanding and reference\"\n",
    "}\n",
    "\n",
    "# Setup the prompt templates\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly skilled data scientist with 20 years of experience. You specialize in writing clean, efficient, and error-free ML code. Generate only the code snippets without any explanations or comments.\"),\n",
    "    human_prompt\n",
    "])\n",
    "\n",
    "model = Ollama(model=\"llama3\")\n",
    "\n",
    "# Function to generate code with LLM\n",
    "\n",
    "\n",
    "def generate_code_snippet(request):\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to generate code with placeholder data\n",
    "\n",
    "\n",
    "def generate_code_snippet_with_placeholder(request, placeholder_data):\n",
    "    placeholder_request = request + \\\n",
    "        f\"\\nUse the following placeholder data:\\n{placeholder_data}\"\n",
    "    formatted_request = chat_prompt.format_prompt(\n",
    "        request=placeholder_request).to_messages()\n",
    "    response = model.invoke(formatted_request)\n",
    "    generated_code = response\n",
    "    return generated_code\n",
    "\n",
    "# Function to clean and correct the code\n",
    "\n",
    "\n",
    "def clean_and_correct_code(generated_code, csv_path):\n",
    "    cleaned_code = generated_code.replace(\"```\", \"\").strip()\n",
    "    cleaned_code_lines = cleaned_code.split(\"\\n\")\n",
    "    cleaned_code_lines = [\n",
    "        line for line in cleaned_code_lines if not line.lower().startswith(\"here is the\")]\n",
    "    cleaned_code = \"\\n\".join(cleaned_code_lines)\n",
    "    if \"python\" in cleaned_code:\n",
    "        cleaned_code = cleaned_code.split(\"python\")[1].strip()\n",
    "    corrected_code = cleaned_code.replace(\"{csv_path}\", f\"{csv_path}\")\n",
    "    return corrected_code\n",
    "\n",
    "# Load dataset information\n",
    "\n",
    "\n",
    "def get_dataset_info(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    columns = df.columns.tolist()\n",
    "    types = df.dtypes.to_dict()\n",
    "    sample_data = df.head().to_dict(orient='list')\n",
    "    value_counts = {col: df[col].value_counts().to_dict()\n",
    "                    for col in df.columns}\n",
    "    description = df.describe().to_dict()\n",
    "    return columns, types, sample_data, value_counts, description\n",
    "\n",
    "# Function to get selected workflow steps based on step numbers\n",
    "\n",
    "\n",
    "def get_selected_steps(step_numbers):\n",
    "    selected_steps = [workflow_steps[num]\n",
    "                      for num in step_numbers if num in workflow_steps]\n",
    "    return selected_steps\n",
    "\n",
    "# Function to validate a single unit code snippet\n",
    "\n",
    "\n",
    "def validate_unit_code(code_filename):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", code_filename], capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(result.stderr)\n",
    "        return True, result.stdout\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Function to generate documentation for a step\n",
    "def generate_documentation(step, columns_info, types_info, sample_data_info, value_counts_info, description_info):\n",
    "    request = (\n",
    "        f\"Provide a clear and concise description of the job performed by the code for the following step: {step}. \"\n",
    "        f\"The description should summarize the main tasks and key points without going into the specifics of the code. \"\n",
    "        f\"The dataset has the following columns: {columns_info}. \"\n",
    "        f\"The data types are: {types_info}. Sample data: {sample_data_info}. Value counts: {value_counts_info}. \"\n",
    "        f\"Description: {description_info}.\"\n",
    "    )\n",
    "    documentation = generate_code_snippet(request)\n",
    "    return documentation\n",
    "\n",
    "# Function to fix the code based on the error\n",
    "def fix_code(code_snippet, error_message, csv_path):\n",
    "    request = (\n",
    "        f\"The following code snippet encountered an error:\\n\\n{code_snippet}\\n\\n\"\n",
    "        f\"Error message:\\n{error_message}\\n\\n\"\n",
    "        f\"Please fix the code snippet to resolve the error without providing any explanations or comments.\"\n",
    "    )\n",
    "    fixed_code = generate_code_snippet(request)\n",
    "    cleaned_fixed_code = clean_and_correct_code(fixed_code, csv_path)\n",
    "    return cleaned_fixed_code\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    csv_path = \"/Users/ilya/Desktop/GitHub_Repositories/HW_University/Data_Mining/datasets/insurance.csv\"\n",
    "    columns, types, sample_data, value_counts, description = get_dataset_info(\n",
    "        csv_path)\n",
    "\n",
    "    columns_info = \", \".join(columns)\n",
    "    types_info = \", \".join([f\"{col}: {typ}\" for col, typ in types.items()])\n",
    "    sample_data_info = \", \".join(\n",
    "        [f\"{col}: {vals[:5]}\" for col, vals in sample_data.items()])\n",
    "    value_counts_info = \", \".join(\n",
    "        [f\"{col}: {dict(list(vc.items())[:5])}\" for col, vc in value_counts.items()])\n",
    "    description_info = \", \".join(\n",
    "        [f\"{col}: {desc}\" for col, desc in description.items()])\n",
    "\n",
    "    # Hardcode the selected step numbers (replace with dynamic selection later)\n",
    "    selected_step_numbers = [ 11, 21, 22, 31, 32, 35, 51, 52, 53, 61, 62]\n",
    "\n",
    "    # Get selected workflow steps based on step numbers\n",
    "    selected_steps = get_selected_steps(selected_step_numbers)\n",
    "\n",
    "    # Generate and validate code snippets for each selected step\n",
    "    documentation_snippets = []\n",
    "    script_code = \"\"\n",
    "    placeholder_data = \"\"\n",
    "    for i, step in enumerate(selected_steps):\n",
    "        request = (\n",
    "            f\"Write a Python code snippet for the following step: {step}. \"\n",
    "            f\"Use placeholders like {csv_path} for dynamic inputs. The dataset has the following columns: {columns_info}. \"\n",
    "            f\"The data types are: {types_info}. Sample data: {sample_data_info}. Value counts: {value_counts_info}. \"\n",
    "            f\"Description: {description_info}. Only return the code without any explanations.\"\n",
    "        )\n",
    "\n",
    "        if placeholder_data:\n",
    "            code_snippet = generate_code_snippet_with_placeholder(\n",
    "                request, placeholder_data)\n",
    "        else:\n",
    "            code_snippet = generate_code_snippet(request)\n",
    "\n",
    "        cleaned_code_snippet = clean_and_correct_code(code_snippet, csv_path)\n",
    "        script_code += cleaned_code_snippet + \"\\n\\n\"\n",
    "\n",
    "        documentation_snippet = generate_documentation(\n",
    "            step, columns_info, types_info, sample_data_info, value_counts_info, description_info)\n",
    "        documentation_snippets.append(documentation_snippet)\n",
    "\n",
    "        placeholder_data += cleaned_code_snippet + \"\\n\\n\"\n",
    "\n",
    "    # Write the entire script code to a file\n",
    "    with open(\"script.py\", \"w\") as file:\n",
    "        file.write(script_code)\n",
    "\n",
    "    # Execute the script and capture the output and errors\n",
    "    success, output = validate_unit_code(\"script.py\")\n",
    "    while not success:\n",
    "        print(\"Validation failed for the script.\")\n",
    "        print(f\"Error: {output}\")\n",
    "        fixed_script_code = fix_code(script_code, output, csv_path)\n",
    "        with open(\"script.py\", \"w\") as file:\n",
    "            file.write(fixed_script_code)\n",
    "        success, output = validate_unit_code(\"script.py\")\n",
    "\n",
    "    if success:\n",
    "        print(\"Script executed successfully.\")\n",
    "        # Save documentation to a separate file\n",
    "        with open(\"documentation.txt\", \"w\") as file:\n",
    "            file.write(\"\\n\".join(documentation_snippets))\n",
    "        print(\"Documentation saved to documentation.txt\")\n",
    "    else:\n",
    "        print(\"Script execution failed.\")\n",
    "        print(f\"Error: {output}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
